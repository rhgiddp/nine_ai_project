{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP3tTskEDgpFtzGE0cOpqo5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Prompt Engineering 파트 실습 4 - 2. 잘 알려진 기법들\n","\n","- 몇몇 잘 알려진 기법들에 대해서 이야기 예정\n","- 단순하게 설명보다는 각 기법 별로 논문 기반으로 원리를 설명 예정\n","- 논문 따로 안 읽으셔도 되고 영어 Prompt 이해 안 되시더라도 구두로 해석 예정이니 학습에 무방함\n","\n","### 목차\n","1. 기법들에 대한 설명\n","  - 시작하기 좋은 포인트\n","  - 어떤 원리로 워킹하는 지를 이해\n","3. 주요 기법들 소개\n","  1. Few-Shot\n","  2. Chain-of-Thought\n","4. 주요 기법들을 응용한 케이스들 소개\n","  1. Self-Consistency\n","  2. Generated Knowledge\n","  3. Least-to-Most\n","  4. Prompt Chaining\n","  5. ReAct\n"],"metadata":{"id":"MlEKRcvS9igd"}},{"cell_type":"markdown","source":["### 들어가기 전에: Zero-Shot Prompting?\n","\n","- Zero-Shot이란 추가적인 학습이나 예시/시연 없이 바로 답변 출력을 유도하는 법\n","  - ChatGPT 전에는 어떤 태스크 진행을 위해서는 데이터 학습이 필요했음\n","  - 그러나 ChatGPT 3.5, GPT-4, Claude 3 같은 LLM은 추가 학습이나 예시가 없어도 어느 정도 잘 답변하는 편\n","  - 2022년 ChatGPT 출시 이후 2024년 기준 ChatGPT한테 바로 질문하는 것은 자연스러운 행위"],"metadata":{"id":"YeApGC7NnPcv"}},{"cell_type":"markdown","source":["### 기법들 설명\n","- 대표적으로는 Few Shot 그리고 Chain of Thought 이렇게 2가지 기법들이 존재함\n","- 그 외에도 많이 있는데, 대부분이 Chain of Thought를 기반으로 발전한 기법들\n","\n","- LLM처럼 특정 Prompt 방법론이 다른 방법론보다 무조건 더 우위에 있고 그런 경향은 없음\n","  - GPT-4가 GPT 3.5 대비 모든 지표에서 더 좋음 (물론 비용, 속도 제외)\n","  - 특정 Prompt 기법 A가 보편적으로 기법 B보다 좋은 케이스는 거의 존재하지 않음\n","- 따라서 각 Prompt Engineering 기법의 원리를 잘 이해하고 유즈케이스를 잘 판단하는게 매우 중요함"],"metadata":{"id":"o59_PNbH_mIE"}},{"cell_type":"markdown","source":["### 주요 기법들 소개\n","\n","### 1. Few-Shot\n","  - 참고 할 수 있는 정답 사례들을 Prompt에 추가하여 성능을 높이는 방법\n","  - Language Models are Few-Shot Learners 논문 (NeurIPS 2020, OpenAI)\n","    - 논문: https://arxiv.org/abs/2005.14165 (=GPT-3 논문)\n","\n","![](https://drive.google.com/uc?export=view&id=1NN1HHJ5-zN_O7vOr--9k7NuC9AMpcDYz)\n","\n","  - Few Shot 의미\n","    - 5-shot의 경우 참고 할 정답 사례들을 Prompt에 5개를 입력해줬다는 뜻\n","    - LLM 평가지표 보면 MMLU(5-shot) 이렇게 적혀있는게 바로 Few-Shot을 적용했다는 뜻\n","    - 평가에서도 사용될만큼 공인된 Prompt Engineering 방법론\n","      - OpenAI에서 GPT-4 벤치마크 할 때 모든 Prompt에 Few-Shot 적용했음\n","- 특징은 모델 사이즈가 어느 정도 커야한다는 점"],"metadata":{"id":"0wmPSSn8Aj_M"}},{"cell_type":"markdown","source":["![](https://drive.google.com/uc?export=view&id=1kw-xSJOLVTkECXhD8_Y5IUN99RKvyorM)\n","\n","출처: Brown et al. (2020) in \"Language Models are Few-Shot Learners\" (Figure 1.2)"],"metadata":{"id":"tsGGdEvDUmdl"}},{"cell_type":"markdown","source":["#### Few-Shot이 잘 워킹하는 이유\n","- 모델의 파라미터를 수정하지 않고 (즉, 추가적인 학습을 하지 않고) 단순하게 Prompt에 예시 정답만 추가해도 성능이 급격하게 증가하는 것을 발견\n","- Pretraining, 즉 사전훈련 단계에서 언어 모델이 패턴을 인지하는 능력을 발달\n","- 이러한 능력으로 추론 시에 태스크에 빠르게 적응을 합니다.\n","- 이렇게 따로 학습을 하지 않고도 언어 모델이 Prompt을 읽으면서 이해해나가는 과정을 \"In-Context Learning\"이라고 불믐\n","\n","![](https://drive.google.com/uc?export=view&id=1HKA26jWkZW1gbKdVsUROM9xSy6aEUj4u)"],"metadata":{"id":"vSCQ6aW8XpeJ"}},{"cell_type":"markdown","source":["#### 이해를 돕기 위한 토막 지식: Pretraining\n","기본적으로 모든 LLM은 아래와 같은 학습 과정을 거침\n","1. Pretraining\n","  - 기본적인 언어 능력을 탑재하는 단계\n","  - 엄청나게 많은 텍스트를 쭉 읽고 학습하는 과정\n","  - 모델 성능에 가장 많이 영향을 끼치는 단계\n","  - 큰 모델들은 Pretraining만 거쳐도 일반적인 태스크 수행이 가능\n","2. Supervised Fine-tuning (SFT)\n","  - 태스크에 맞춰서 추가로 학습하는 단계\n","  - 보통 입력과 정답 쌍이 있어 이 쌍을 학습하는 과정\n","3. Human Alignment Training (ex. RLHF, DPO, ORPO)\n","  - 사람이 선호하는 답변이 무엇인지 학습하는 단계\n","  - 방법은 여러 가지가 있는데 가장 단순하게는 좋은 답변 A, 좋지 않은 답변 B 쌍을 두고 학습하는 과정"],"metadata":{"id":"0DNb_PIMjRwT"}},{"cell_type":"code","source":["!pip install openai --quiet"],"metadata":{"id":"C0NrHnB4YL_s","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714141113536,"user_tz":-540,"elapsed":27418,"user":{"displayName":"Marko","userId":"13892425088441002710"}},"outputId":"795b26c6-b7df-4f37-f385-9b36208442ff"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.6/311.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["from google.colab import userdata\n","\n","OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')"],"metadata":{"id":"iYMufzI-pOLx","executionInfo":{"status":"ok","timestamp":1714141117178,"user_tz":-540,"elapsed":1305,"user":{"displayName":"Marko","userId":"13892425088441002710"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["from openai import OpenAI\n","\n","client = OpenAI(\n","    api_key=OPENAI_API_KEY\n",")"],"metadata":{"id":"j3itJM_ypRwi","executionInfo":{"status":"ok","timestamp":1714141130027,"user_tz":-540,"elapsed":1705,"user":{"displayName":"Marko","userId":"13892425088441002710"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["#### Few-Shot 예시\n","- LLaMA 논문 Figure 3 (https://arxiv.org/pdf/2302.13971.pdf)"],"metadata":{"id":"Z0enizVnBr5X"}},{"cell_type":"code","source":["prompt = \"\"\"Q: Who wrote the book the origin of species?\n","\"\"\"\n","\n","completion = client.chat.completions.create(\n","    model='gpt-3.5-turbo-0125',\n","    messages=[{'role': 'user', 'content': prompt}],\n","    temperature=0.0\n",")\n","\n","print(completion.choices[0].message.content)"],"metadata":{"id":"XIm6ET57pdnm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714141212555,"user_tz":-540,"elapsed":995,"user":{"displayName":"Marko","userId":"13892425088441002710"}},"outputId":"14adb767-0f57-40fa-9df6-70f0145b72db"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Charles Darwin wrote the book \"On the Origin of Species\" in 1859.\n"]}]},{"cell_type":"code","source":["prompt = \"\"\"Answer these questions:\n","Q: Who sang who wants to be a millionaire in high society?\n","A: Frank Sinatra\n","Q: Who wrote the book the origin of species?\n","A: \"\"\"\n","\n","completion = client.chat.completions.create(\n","    model='gpt-3.5-turbo-0125',\n","    messages=[{'role': 'user', 'content': prompt}],\n","    temperature=0.0\n",")\n","\n","print(completion.choices[0].message.content)"],"metadata":{"id":"ucaoC3F5oxY4","executionInfo":{"status":"ok","timestamp":1714141263896,"user_tz":-540,"elapsed":739,"user":{"displayName":"Marko","userId":"13892425088441002710"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"84138a7f-c75f-4a25-f533-dfdcd9f0645a"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Charles Darwin\n"]}]},{"cell_type":"markdown","source":["### Few-Shot 장단점\n","\n","- 말 그대로 정답 예시만 넣어주면 되기 때문에 정답이 존재하는 모든 케이스에 적용이 가능함!\n","  - Prompt 길이가 길어 질 수 있는데 속도와 특히 비용에 영향이 존재\n","    - 정답 예시가 굉장히 긴 경우"],"metadata":{"id":"2piEz7zOqUUC"}},{"cell_type":"markdown","source":["### 2. Chain-of-Thought\n","  - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models (NeurIPS 2022, Google)\n","    - 논문: https://arxiv.org/abs/2201.11903\n","  - Few Shot이 참고 할 수 있는 정답 사례들을 Prompt에 추가하여 성능을 높이는 방법이라면 Chain of Thought는 거기에 추가로 문제 해결 과정도 같이 Prompt에 추가하는 방식\n","  - 대부분의 Prompt Engineering 기법은 Chain-of-Thought의 후속작"],"metadata":{"id":"HSa5b1ksBwbU"}},{"cell_type":"markdown","source":["![](https://drive.google.com/uc?export=view&id=1nObDipl_b3pGipuc3ui575hJuP15WcMA)\n","\n","출처: Chain-of-Thought 논문"],"metadata":{"id":"8k1MJGxLtScG"}},{"cell_type":"markdown","source":["- 안타깝게도 Chain-of-Thought 논문에 있는 모든 예시들은 gpt-3.5-turbo-0125로는 재현되지 않음\n","- CoT 없이 못 푸는 문제들 없이 이미 다 잘 해결함\n","  - 따라서 예시를 입력하는 것보다는 원리를 잘 이해하는게 중요"],"metadata":{"id":"1Dwfdrv_9LIg"}},{"cell_type":"code","source":["# Prompt 출처: https://github.com/microsoft/generative-ai-for-beginners/tree/main/05-advanced-prompts\n","\n","prompt = \"\"\"Alice has 5 apples, throws 3 apples, gives 2 to Bob and Bob gives one back, how many apples does Alice have?\"\"\"\n","\n","completion = client.chat.completions.create(\n","    model=\"gpt-3.5-turbo-0125\",\n","    messages=[{\"role\": \"user\", \"content\": prompt}],\n","    temperature=0.0\n",")\n","\n","print(completion.choices[0].message.content)"],"metadata":{"id":"Uf_8_uLUq96v","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714141625056,"user_tz":-540,"elapsed":1381,"user":{"displayName":"Marko","userId":"13892425088441002710"}},"outputId":"62e8059f-b55e-4c21-8cac-465da6714a58"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Alice would have 5 apples - 3 thrown + 2 given to Bob - 1 given back = 3 apples. \n","\n","Therefore, Alice would have 3 apples.\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"7xY_52V_zJ_F"}},{"cell_type":"code","source":["prompt = \"\"\"Lisa has 7 apples, throws 1 apple, gives 4 apples to Bart and Bart gives one back:\n","7 - 1 = 6\n","6 - 4 = 2\n","2 + 1 = 3\n","\n","Alice has 5 apples, throws 3 apples, gives 2 to Bob and Bob gives one back, how many apples does Alice have?\"\"\"\n","\n","completion = client.chat.completions.create(\n","    model=\"gpt-3.5-turbo-0125\",\n","    messages=[{\"role\": \"user\", \"content\": prompt}],\n","    temperature=0.0\n",")\n","\n","print(completion.choices[0].message.content)"],"metadata":{"id":"lRTC6cbS70oJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714141710350,"user_tz":-540,"elapsed":1256,"user":{"displayName":"Marko","userId":"13892425088441002710"}},"outputId":"4a4ebdff-755a-4aef-a8ca-858bb45e902c"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["5 - 3 = 2\n","2 - 2 = 0\n","0 + 1 = 1\n","\n","Alice has 1 apple left.\n"]}]},{"cell_type":"code","source":["# Prompt 출처: https://github.com/microsoft/generative-ai-for-beginners/tree/main/05-advanced-prompts\n","\n","prompt = \"\"\"Alice has 5 apples, throws 3 apples, gives 2 to Bob and Bob gives one back, how many apples does Alice have?\"\"\"\n","\n","completion = client.chat.completions.create(\n","    model=\"gpt-4-turbo-2024-04-09\",\n","    messages=[{\"role\": \"user\", \"content\": prompt}],\n","    temperature=0.0\n",")\n","\n","print(completion.choices[0].message.content)"],"metadata":{"id":"Gk9aNv816l4p","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714141763166,"user_tz":-540,"elapsed":6601,"user":{"displayName":"Marko","userId":"13892425088441002710"}},"outputId":"2b1bdccd-c9fd-49ee-948b-84d12d3efd6e"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Let's break down the sequence of events to determine how many apples Alice has at the end:\n","\n","1. Alice starts with 5 apples.\n","2. Alice throws 3 apples away. Now she has 5 - 3 = 2 apples.\n","3. Alice gives 2 apples to Bob. Now she has 2 - 2 = 0 apples.\n","4. Bob gives 1 apple back to Alice. Now she has 0 + 1 = 1 apple.\n","\n","Therefore, Alice has 1 apple left.\n"]}]},{"cell_type":"markdown","source":["## 주요 기법들을 응용한 케이스들 소개\n","- Self-Consistency\n","  - CoT 한 번이 아니라 여러 번의 다양한 CoT 과정을 거쳐 그 중 베스트를 선정하는 방법\n","  - Self-Consistency Improves Chain of Thought Reasoning in Language Models (2022)\n","    - 논문: https://arxiv.org/pdf/2203.11171.pdf\n","  - 한 수 더 떠서 더 다양하게 그리고 각 CoT 과정들을 연결한 Tree of Thought 논문도 존재\n","- Generated Knowledge\n","  - 질문을 통해 상식을 끄집어내어 더 정확하게 대답하는 방법\n","  - Generated Knowledge Prompting for Commonsense Reasoning (2022)\n","    - 논문: https://arxiv.org/pdf/2110.08387.pdf\n","  - 해당 상식을 어느 정도 알고 있다는 전제 하에 워킹할만한 방법\n","  - Retrieval Augmented Generation(RAG)은 상식을 직접 주입하는 방법\n","    - 별도의 RAG 로직이 필요하지만 이게 실제로 많이 활용되는 방법 (자세한건 RAG 파트에서)\n","- Least-to-Most\n","  - 질문 A를 바로 물어보지 않고 질문 a, b로 쪼개서 물어보는 분할 정복 방법\n","  - Least-to-Most Prompting Enables Complex Reasoning in Large Language Models (2022)\n","    - 논문: https://arxiv.org/pdf/2205.10625\n","  - 비용 증가로 이어지긴 하나 상대적으로 사용하기 쉬운 방법\n","- Prompt Chaining\n","  - Prompt A의 Output A를 Prompt B에 사용하는 방법\n","  - 주로 전처리 또는 답변을 하기 쉽게 만드는 Prompt A와 실제 답변을 유도하는 Prompt B로 구성\n","  - Least-to-Most처럼 분할 정복 계열\n","- ReAct\n","  - Chain-of-Thought에서 Reasoning 과정을 추가한다면 여기서는 Reasoning 외에도 Action까지 추가하는 방법\n","  - 실제로 환경과 interact 해야하는 상황을 가정한 방법론\n","  - ReAct: Synergizing Reasoning and Acting in Language Models (2022)\n","    - 논문: https://arxiv.org/abs/2210.03629\n","\n","-----\n","\n","실용적인 방법론이 많진 않지만, CoT 논문 이후로 여러 다양한 방법론을 찾기 위한 많은 연구 결과물들\n","- 실용적이지 않은 이유에는 Input 토큰이 몇 배씩 증가하여 비용 이슈로 이어질 수 있기 때문"],"metadata":{"id":"exjpdd3A8wPo"}},{"cell_type":"markdown","source":["### Self-Consistency\n","- 실제로 쓰기엔 좀 애매함. 출력값 Voting 앙상블인데 사실 대부분의 머신러닝 케이스에서 앙상블은 효율은 안 좋은 편 (순수하게 성능 향상은 꽤 좋은 편)\n","  - 앙상블(Ensemble) = 2개 이상의 모델 또는 모델 출력값을 합쳐 성능을 높이는 방법\n","\n","![](https://drive.google.com/uc?export=view&id=1UNYm2QhHxmCPVBM40XEXzBamwsxcWJ0a)\n","\n","출처: Self-Consistency 논문"],"metadata":{"id":"RtNnmA_4AvsG"}},{"cell_type":"markdown","source":["## 정리\n","- 우리가 ChatGPT한테 Naive하게 바로 질문하는 방법은 \"Zero-Shot Prompting\"으로 간주됨\n","- Zero-Shot보다 더 좋은 방법론은 대표적으로 Few Shot, Chain-of-Thought\n","  - Few-Shot은 Prompt에 예시 정답을 추가, Chain-of-Thought는 여기에 추가적으로 정답 추리 과정까지 넣어주는 방법\n","- 그 외에도 다른 방법들이 존재하면 대부분 위 두 방법론을 응용한 케이스들\n","- 위에 언급한 논문들은 한 번씩 가볍게 읽어보시는 것을 추천\n","  - 정독보다는 기존 방법론을 어떻게 개선하려 했는지 포인트만 이해하는 것을 권장"],"metadata":{"id":"BXUP9VUuEbBn"}},{"cell_type":"code","source":[],"metadata":{"id":"uMYrxswWIBRU"},"execution_count":null,"outputs":[]}]}