{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline 모델 개발 및 평가 지표 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using standard tqdm (text-based progress bar)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\FAST_CAMF\\Nine_Project_Github\\kakaotalk-summarization\\.conda-kakao\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import re\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# 현재 디렉토리를 Python 경로에 추가\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "# tqdm import - ipywidgets 문제를 피하기 위해 일반 tqdm 사용\n",
    "from tqdm import tqdm\n",
    "print(\"Using standard tqdm (text-based progress bar)\")\n",
    "\n",
    "from eval import get_eval_data, pointwise_eval\n",
    "from utils import summarize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "비용 기반 후보 모델 선정\n",
    "- Claude 3 Haiku\n",
    "- Gemini 1.5 Flash\n",
    "- ChatGPT 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_BASELINE = f\"\"\"아래 사용자 대화에 대해 3문장 내로 요약해주세요:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P01: 맞다요즘 싸이월드 새로 생겼다매\n",
      "P02: 나 싸이월드 복구하고 싶다\n",
      "P01: 웅 키키귀여우뉴사진\n",
      "P02: 진짜 추억돋네\n",
      "P01: 짱많아 옛날 사진들\n",
      "P01: 맨날 퍼가요~ 이거 했자나\n",
      "P02: 맞아 싸이월드 미니미\n",
      "P01: 추억 돋아서 너무조아\n",
      "P02: 꾸미는거\n",
      "P01: 마자\n",
      "P02: 재밌었는데\n",
      "P01: 귀여워 도토리충전\n",
      "P02: 네이트온도 하고\n",
      "P02: 도토리도 환불해준대자나\n",
      "P01: 마자 키키개웃겨\n",
      "P01: 요즘 사회적으로 멀 자꾸하나바\n",
      "P02: 대박이야 진짜\n",
      "P02: 그니깐 키키\n",
      "P01: 아니 나오늘 엄마가 뭐 신청해달라그래서\n",
      "P02: 웅\n",
      "P01: 지원금 ? 신청함\n",
      "P01: 진짜 요즘 지원금 엄청 많이 받았어\n",
      "P02: 와 대박\n",
      "P01: 뭔지는 잘 모르는데 이것저것 지원해주는거 많아서 좋은듯\n",
      "P02: 다행이다\n",
      "P01: 국가제도가 진짜 괜차나\n",
      "P01: 학교에서도\n",
      "P02: 두분다\n",
      "P01: 맨날 장학금 해준다고\n",
      "P02: 일을 못하는\n",
      "P01: 이것저것 지원해주자나\n",
      "P02: 상황이셔서 더\n",
      "P01: 마자ㅠㅠ\n",
      "P02: 도움주시고\n",
      "P01: 나 그래서 진짜 그런거로\n",
      "P02: 다행이다그래도\n",
      "P01: 돈 마니받앗어\n",
      "P02: 와대박\n"
     ]
    }
   ],
   "source": [
    "print(get_eval_data()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 두 사람은 과거 싸이월드 사용 경험을 회상하며 추억을 공유하고 있다.\n",
      "2. 최근 정부와 학교에서 제공하는 다양한 지원금 혜택에 대해 이야기하고 있다.\n",
      "3. 이러한 지원금 덕분에 경제적으로 어려운 상황에서도 도움을 받고 있다고 말하고 있다.\n",
      "The AI assistant's response provides a concise summary of the conversation, capturing the main points discussed by the users. It accurately identifies the two main topics: reminiscing about Cyworld and discussing various support funds. However, the response could be improved by offering more specific details or insights into the conversation's context or emotional tone. Overall, the response is relevant and accurate but lacks depth.\n",
      "\n",
      "Rating: [[7]]\n"
     ]
    }
   ],
   "source": [
    "summary = summarize(\n",
    "    conversation=get_eval_data()[0],\n",
    "    prompt=PROMPT_BASELINE,\n",
    "    model='claude-3-haiku-20240307'\n",
    ")\n",
    "eval_comment = pointwise_eval(get_eval_data()[0], summary)\n",
    "\n",
    "print(summary)\n",
    "print(eval_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "두 사용자는 새로 나온 싸이월드에 대한 추억을 회상하며 미니미 꾸미기, 도토리 충전 등의 경험을 이야기합니다. 대화 후반부에는 P01이 어머니의 지원금 신청을 도와준 경험을 공유하며 국가 및 학교의 다양한 지원 제도가 도움이 된다는 점을 강조합니다. P02는 P01의 부모님 상황을 언급하며 국가 지원 덕분에 다행이라는 반응을 보입니다.\n",
      "\n",
      "The AI assistant's response provides a clear and accurate summary of the conversation between the two users. It captures the main points discussed, including the nostalgia for Cyworld and the various support systems available. However, the response could be improved by being more concise and focusing on the most relevant details. Overall, it is helpful and relevant but could benefit from slight refinement.\n",
      "\n",
      "Rating: [[8]]\n"
     ]
    }
   ],
   "source": [
    "summary = summarize(\n",
    "    conversation=get_eval_data()[0],\n",
    "    prompt=PROMPT_BASELINE,\n",
    "    model='gemini-2.0-flash-001'\n",
    ")\n",
    "eval_comment = pointwise_eval(get_eval_data()[0], summary)\n",
    "\n",
    "print(summary)\n",
    "print(eval_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "두 사용자는 싸이월드를 통해 추억을 공유하고, 최근 받은 지원금에 대해 이야기하며 국가제도에 대한 긍정적인 평가를 나누었습니다.\n",
      "The AI assistant's response provides a brief summary of the conversation, capturing the main points about the users reminiscing over Cyworld and discussing recent support funds and positive views on national policies. However, the summary is somewhat superficial and does not delve into the nuances or specific details of the conversation. It could have been more detailed to better reflect the depth of the users' exchange.\n",
      "\n",
      "Rating: [[6]]\n"
     ]
    }
   ],
   "source": [
    "summary = summarize(\n",
    "    conversation=get_eval_data()[0],\n",
    "    prompt=PROMPT_BASELINE,\n",
    "    model='gpt-3.5-turbo-0125',\n",
    ")\n",
    "eval_comment = pointwise_eval(get_eval_data()[0], summary)\n",
    "\n",
    "print(summary)\n",
    "print(eval_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "처리 중: claude-3-haiku-20240307\n",
      "  진행률: 1/50\n",
      "  진행률: 2/50\n",
      "  진행률: 3/50\n",
      "  진행률: 4/50\n",
      "  진행률: 5/50\n",
      "  진행률: 6/50\n",
      "  진행률: 7/50\n",
      "  진행률: 8/50\n",
      "  진행률: 9/50\n",
      "  진행률: 10/50\n",
      "  진행률: 11/50\n",
      "  진행률: 12/50\n",
      "  진행률: 13/50\n",
      "  진행률: 14/50\n",
      "  진행률: 15/50\n",
      "  진행률: 16/50\n",
      "  진행률: 17/50\n",
      "  진행률: 18/50\n",
      "  진행률: 19/50\n",
      "  진행률: 20/50\n",
      "  진행률: 21/50\n",
      "  진행률: 22/50\n",
      "  진행률: 23/50\n",
      "  진행률: 24/50\n",
      "  진행률: 25/50\n",
      "  진행률: 26/50\n",
      "  진행률: 27/50\n",
      "  진행률: 28/50\n",
      "  진행률: 29/50\n",
      "  진행률: 30/50\n",
      "  진행률: 31/50\n",
      "  진행률: 32/50\n",
      "  진행률: 33/50\n",
      "  진행률: 34/50\n",
      "  진행률: 35/50\n",
      "  진행률: 36/50\n",
      "  진행률: 37/50\n",
      "  진행률: 38/50\n",
      "  진행률: 39/50\n",
      "  진행률: 40/50\n",
      "  진행률: 41/50\n",
      "  진행률: 42/50\n",
      "  진행률: 43/50\n",
      "  진행률: 44/50\n",
      "  진행률: 45/50\n",
      "  진행률: 46/50\n",
      "  진행률: 47/50\n",
      "  진행률: 48/50\n",
      "  진행률: 49/50\n",
      "  진행률: 50/50\n",
      "완료: claude-3-haiku-20240307 - 50개 점수 수집\n",
      "처리 중: gemini-2.0-flash\n",
      "  진행률: 1/10\n",
      "  진행률: 2/10\n",
      "  진행률: 3/10\n",
      "  진행률: 4/10\n",
      "  진행률: 5/10\n",
      "  진행률: 6/10\n",
      "  진행률: 7/10\n",
      "  진행률: 8/10\n",
      "  진행률: 9/10\n",
      "  진행률: 10/10\n",
      "완료: gemini-2.0-flash - 10개 점수 수집\n",
      "처리 중: gpt-3.5-turbo-0125\n",
      "  진행률: 1/10\n",
      "  진행률: 2/10\n",
      "  진행률: 3/10\n",
      "  진행률: 4/10\n",
      "  진행률: 5/10\n",
      "  진행률: 6/10\n",
      "  진행률: 7/10\n",
      "  진행률: 8/10\n",
      "  진행률: 9/10\n",
      "  진행률: 10/10\n",
      "완료: gpt-3.5-turbo-0125 - 10개 점수 수집\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    'claude-3-haiku-20240307',\n",
    "    'gemini-2.0-flash',  # Gemini 2.0 Flash 실험 버전\n",
    "    'gpt-3.5-turbo-0125'\n",
    "]\n",
    "scores = {model: [] for model in models}\n",
    "pattern = r'\\[\\[\\d+\\]\\]'\n",
    "\n",
    "for model in models:\n",
    "    print(f\"처리 중: {model}\")\n",
    "    eval_data = get_eval_data()  # 한 번만 호출하여 성능 향상\n",
    "    \n",
    "    # 모델별로 최대 처리 개수 제한 (테스트용)\n",
    "    max_items = 10 if model != 'claude-3-haiku-20240307' else len(eval_data)\n",
    "    \n",
    "    for i in range(min(len(eval_data), max_items)):\n",
    "        print(f\"  진행률: {i+1}/{min(len(eval_data), max_items)}\")\n",
    "        try:\n",
    "            summary = summarize(\n",
    "                conversation=eval_data[i],\n",
    "                prompt=PROMPT_BASELINE,\n",
    "                model=model\n",
    "            )\n",
    "            eval_comment = pointwise_eval(eval_data[i], summary)\n",
    "            match = re.search(pattern, eval_comment)\n",
    "            if match:\n",
    "                matched_string = match.group(0)\n",
    "                score = int(matched_string[2])\n",
    "                scores[model].append(score)\n",
    "            else:\n",
    "                print(f\"    경고: 점수 패턴을 찾을 수 없음 - {eval_comment}\")\n",
    "        except Exception as e:\n",
    "            print(f\"    에러: {e}\")\n",
    "            # 연속 에러가 발생하면 해당 모델 건너뛰기\n",
    "            if i > 2:  # 처음 몇 개 에러는 무시하고 계속\n",
    "                print(f\"    모델 {model}에서 연속 에러 발생, 건너뛰기\")\n",
    "                break\n",
    "            continue\n",
    "    print(f\"완료: {model} - {len(scores[model])}개 점수 수집\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "claude-3-haiku-20240307: [8, 8, 6, 8, 6, 7, 8, 8, 6, 7, 4, 6, 4, 6, 7, 7, 8, 5, 5, 7, 8, 6, 8, 6, 6, 6, 7, 5, 6, 6, 6, 7, 6, 7, 7, 7, 7, 8, 8, 5, 8, 8, 8, 7, 8, 8, 7, 4, 5, 4]\n",
      "claude-3-haiku-20240307: 6.6 / 1.25\n",
      "gemini-2.0-flash: [9, 8, 9, 8, 7, 7, 7, 7, 7, 9]\n",
      "gemini-2.0-flash: 7.8 / 0.92\n",
      "gpt-3.5-turbo-0125: [7, 5, 4, 7, 5, 5, 4, 6, 4, 6]\n",
      "gpt-3.5-turbo-0125: 5.3 / 1.16\n"
     ]
    }
   ],
   "source": [
    "for model in scores:\n",
    "    print(f'{model}: {scores[model]}')\n",
    "    mean = sum(scores[model]) / len(scores[model])\n",
    "    variance = sum((x - mean) ** 2 for x in scores[model]) / (len(scores[model]) - 1)\n",
    "    std_dev = math.sqrt(variance)\n",
    "    print(f'{model}: {mean} / {round(std_dev, 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "claude-3-haiku-20240307 8 4\n",
      "gemini-2.0-flash 9 7\n",
      "gpt-3.5-turbo-0125 7 4\n"
     ]
    }
   ],
   "source": [
    "for model in scores:\n",
    "    print(model, max(scores[model]), min(scores[model]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디버깅: 첫 번째 데이터로 테스트\n",
    "try:\n",
    "    test_data = get_eval_data()[0]\n",
    "    print(\"테스트 데이터:\", test_data)\n",
    "    \n",
    "    test_summary = summarize(\n",
    "        conversation=test_data,\n",
    "        prompt=PROMPT_BASELINE,\n",
    "        model='gpt-3.5-turbo-0125'\n",
    "    )\n",
    "    print(\"테스트 요약:\", test_summary)\n",
    "    \n",
    "    test_eval = pointwise_eval(test_data, test_summary)\n",
    "    print(\"테스트 평가:\", test_eval)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"에러 발생: {e}\")\n",
    "    print(f\"에러 타입: {type(e)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
