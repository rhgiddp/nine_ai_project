{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline 모델 개발 및 평가 지표 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import re\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from eval import get_eval_data, pointwise_eval\n",
    "from utils import summarize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "비용 기반 후보 모델 선정\n",
    "- Claude 3 Haiku\n",
    "- Gemini 1.5 Flash\n",
    "- ChatGPT 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_BASELINE = f\"\"\"아래 사용자 대화에 대해 3문장 내로 요약해주세요:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P01: 맞다요즘 싸이월드 새로 생겼다매\n",
      "P02: 나 싸이월드 복구하고 싶다\n",
      "P01: 웅 키키귀여우뉴사진\n",
      "P02: 진짜 추억돋네\n",
      "P01: 짱많아 옛날 사진들\n",
      "P01: 맨날 퍼가요~ 이거 했자나\n",
      "P02: 맞아 싸이월드 미니미\n",
      "P01: 추억 돋아서 너무조아\n",
      "P02: 꾸미는거\n",
      "P01: 마자\n",
      "P02: 재밌었는데\n",
      "P01: 귀여워 도토리충전\n",
      "P02: 네이트온도 하고\n",
      "P02: 도토리도 환불해준대자나\n",
      "P01: 마자 키키개웃겨\n",
      "P01: 요즘 사회적으로 멀 자꾸하나바\n",
      "P02: 대박이야 진짜\n",
      "P02: 그니깐 키키\n",
      "P01: 아니 나오늘 엄마가 뭐 신청해달라그래서\n",
      "P02: 웅\n",
      "P01: 지원금 ? 신청함\n",
      "P01: 진짜 요즘 지원금 엄청 많이 받았어\n",
      "P02: 와 대박\n",
      "P01: 뭔지는 잘 모르는데 이것저것 지원해주는거 많아서 좋은듯\n",
      "P02: 다행이다\n",
      "P01: 국가제도가 진짜 괜차나\n",
      "P01: 학교에서도\n",
      "P02: 두분다\n",
      "P01: 맨날 장학금 해준다고\n",
      "P02: 일을 못하는\n",
      "P01: 이것저것 지원해주자나\n",
      "P02: 상황이셔서 더\n",
      "P01: 마자ㅠㅠ\n",
      "P02: 도움주시고\n",
      "P01: 나 그래서 진짜 그런거로\n",
      "P02: 다행이다그래도\n",
      "P01: 돈 마니받앗어\n",
      "P02: 와대박\n"
     ]
    }
   ],
   "source": [
    "print(get_eval_data()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 두 사람은 과거 싸이월드 사용 경험을 회상하며 추억을 공유하고 있다.\n",
      "2. 최근 정부와 학교에서 제공하는 다양한 지원금 혜택에 대해 이야기하고 있다.\n",
      "3. 경제적 어려움을 겪고 있는 상황에서 이러한 지원이 도움이 되고 있다고 말하고 있다.\n",
      "The AI assistant's response accurately summarizes the key points of the user conversation, highlighting the nostalgic discussion about Cyworld and the conversation about various government and school support funds. The response is relevant and helpful as it captures the essence of the conversation in a concise manner. However, it could be improved by providing more specific details or insights into the conversation.\n",
      "\n",
      "Rating: [[8]]\n"
     ]
    }
   ],
   "source": [
    "summary = summarize(\n",
    "    conversation=get_eval_data()[0],\n",
    "    prompt=PROMPT_BASELINE,\n",
    "    model='claude-3-haiku-20240307'\n",
    ")\n",
    "eval_comment = pointwise_eval(get_eval_data()[0], summary)\n",
    "\n",
    "print(summary)\n",
    "print(eval_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "두 친구는 싸이월드 부활과 추억에 대해 이야기하며 옛날 사진과 미니미, 도토리 등을 떠올립니다. 또한 요즘 사회적으로 지원금과 장학금이 많아졌다는 이야기를 나누며, 국가제도와 학교의 지원에 대해 긍정적인 반응을 보입니다. 특히 한 친구는 다양한 지원금을 받아 돈을 많이 벌었다고 자랑하며 친구의 부러움을 삽니다. \n",
      "\n",
      "The AI assistant's response is a summary of the user conversation, capturing the main points discussed, such as memories of Cyworld, support funds, and scholarships. However, it lacks depth and does not provide any new information or insights that could be helpful to the user. The response is relevant but not particularly useful or engaging.\n",
      "\n",
      "Rating: [[4]]\n"
     ]
    }
   ],
   "source": [
    "summary = summarize(\n",
    "    conversation=get_eval_data()[0],\n",
    "    prompt=PROMPT_BASELINE,\n",
    "    model='gemini-1.5-flash-001'\n",
    ")\n",
    "eval_comment = pointwise_eval(get_eval_data()[0], summary)\n",
    "\n",
    "print(summary)\n",
    "print(eval_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "두 사용자는 싸이월드를 통해 추억을 공유하고, 최근 받은 지원금에 대해 이야기하며 국가제도에 대한 긍정적인 평가를 나누었습니다.\n",
      "The AI assistant's response is a brief summary of the conversation, capturing the main points about the users reminiscing over Cyworld and discussing recent support funds and positive views on national policies. However, it lacks depth and does not provide any additional helpful information or insights that could enhance the conversation. The response is relevant and accurate but could be more engaging and informative.\n",
      "\n",
      "Rating: [[6]]\n"
     ]
    }
   ],
   "source": [
    "summary = summarize(\n",
    "    conversation=get_eval_data()[0],\n",
    "    prompt=PROMPT_BASELINE,\n",
    "    model='gpt-3.5-turbo-0125',\n",
    ")\n",
    "eval_comment = pointwise_eval(get_eval_data()[0], summary)\n",
    "\n",
    "print(summary)\n",
    "print(eval_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eb82380398d43c2acb92803196af10e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8344520a6b046b782f37173a4a264a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1c29a118b694061a90d1ecf60073387",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = [\n",
    "    'claude-3-haiku-20240307',\n",
    "    'gemini-1.5-flash-001',\n",
    "    'gpt-3.5-turbo-0125'\n",
    "]\n",
    "scores = {model: [] for model in models}\n",
    "pattern = r'\\[\\[\\d+\\]\\]'\n",
    "\n",
    "for model in models:\n",
    "    for i in tqdm(range(len(get_eval_data()))):\n",
    "        summary = summarize(\n",
    "            conversation=get_eval_data()[i],\n",
    "            prompt=PROMPT_BASELINE,\n",
    "            model=model\n",
    "        )\n",
    "        eval_comment = pointwise_eval(get_eval_data()[i], summary)\n",
    "        match = re.search(pattern, eval_comment)\n",
    "        matched_string = match.group(0)\n",
    "        score = int(matched_string[2])\n",
    "        scores[model].append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 5, 6, 8, 7, 7, 7, 6, 6, 7, 6, 6, 5, 6, 7, 7, 8, 6, 9, 9, 7, 8, 7, 7, 5, 6, 7, 7, 6, 8, 7, 7, 6, 7, 7, 7, 7, 6, 7, 6, 8, 7, 6, 6, 7, 9, 7, 6, 7, 7] claude-3-haiku-20240307\n",
      "[4, 5, 5, 6, 6, 1, 6, 4, 3, 4, 6, 4, 4, 3, 4, 5, 5, 3, 4, 5, 3, 1, 4, 4, 9, 1, 5, 6, 3, 6, 3, 3, 3, 5, 4, 7, 6, 5, 5, 4, 5, 3, 4, 4, 5, 4, 4, 1, 6, 4] gemini-1.5-flash-001\n",
      "[6, 5, 5, 7, 4, 7, 6, 6, 6, 6, 6, 6, 3, 4, 5, 5, 6, 3, 4, 5, 6, 5, 6, 5, 6, 3, 7, 7, 6, 5, 4, 6, 4, 6, 5, 4, 6, 4, 6, 3, 5, 6, 6, 6, 5, 3, 6, 5, 4, 4] gpt-3.5-turbo-0125\n"
     ]
    }
   ],
   "source": [
    "for model in scores:\n",
    "    print(scores[model], model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "claude-3-haiku-20240307: 6.82 / 0.94\n",
      "gemini-1.5-flash-001: 4.28 / 1.55\n",
      "gpt-3.5-turbo-0125: 5.18 / 1.14\n"
     ]
    }
   ],
   "source": [
    "for model in scores:\n",
    "    mean = sum(scores[model]) / len(scores[model])\n",
    "    variance = sum((x - mean) ** 2 for x in scores[model]) / (len(scores[model]) - 1)\n",
    "    std_dev = math.sqrt(variance)\n",
    "    print(f'{model}: {mean} / {round(std_dev, 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "claude-3-haiku-20240307 9 5\n",
      "gemini-1.5-flash-001 9 1\n",
      "gpt-3.5-turbo-0125 7 3\n"
     ]
    }
   ],
   "source": [
    "for model in scores:\n",
    "    print(model, max(scores[model]), min(scores[model]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
