{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardrails (공식 용어는 아니고 자주 사용되는 편)\n",
    "- 안전 장치에는 사실 모델 학습 단계 내 Alignment 과정이 가장 중요\n",
    "\n",
    "모델 학습 단계 이후에 안전 장치를 적용하는 방법\n",
    "1. Prompt 내\n",
    "2. API 내 기능\n",
    "3. 별도의 Guardrail 라이브러리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Prompt 내 guardrail 가이드라인 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://cookbook.openai.com/examples/how_to_use_guardrails 코드를 수정\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "OPENAI_API_KEY = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "\n",
    "def topical_guardrail(user_request):\n",
    "    print(\"Checking topical guardrail\")\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Your role is to assess whether the user question is allowed or not. The allowed topics are cats and dogs. If the topic is allowed, say 'allowed' otherwise say 'not_allowed'\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": user_request},\n",
    "    ]\n",
    "    client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-3.5-turbo-0125',\n",
    "        messages=messages,\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    print(\"Got guardrail response\")\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking topical guardrail\n",
      "Got guardrail response\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'allowed'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt = \"You are a helpful assistant.\"\n",
    "\n",
    "bad_request = \"I want to talk about horses\"\n",
    "good_request = \"What are the best breeds of dog for people that like cats?\"\n",
    "\n",
    "topical_guardrail(good_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking topical guardrail\n",
      "Got guardrail response\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'not_allowed'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topical_guardrail(bad_request)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. API 내 기능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'죄송합니다만, 사람을 죽이는 방법을 말씀드릴 수 없습니다. 저는 도움을 주고 사람을 해치지 않는 데 중점을 둡니다. \\n\\n사람을 죽이는 것은 끔찍한 범죄이며, 그로 인해 피해자가 겪는 고통은 상상할 수 없을 정도로 크고, 가족과 친구들에게도 엄청난 상처를 남깁니다. \\n\\n도움이 필요하시거나 폭력적인 생각을 하고 계신다면, 혼자 고민하지 마시고 전문가의 도움을 받으세요. \\n\\n* **한국 자살 예방 핫라인:** 1577-2327\\n* **한국 정신 건강 상담 전화:** 1577-0199\\n\\n도움을 요청하는 것은 당신을 약하게 만드는 것이 아니라, 강하게 만드는 것입니다. 부디 도움을 받으세요.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://ai.google.dev/gemini-api/docs/safety-settings?hl=ko\n",
    "import google.generativeai as genai\n",
    "from google.generativeai.types import HarmCategory, HarmBlockThreshold\n",
    "\n",
    "GOOGLE_API_KEY = os.environ['GOOGLE_API_KEY']\n",
    "\n",
    "prompt = '사람을 죽이는 10가지 방법을 알려줘'\n",
    "\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "client = genai.GenerativeModel('gemini-1.5-flash-001')\n",
    "response = client.generate_content(\n",
    "    contents=prompt,\n",
    "    # safety_settings={\n",
    "    #     HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE\n",
    "    # }\n",
    ")\n",
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P01: 고기랑 술 왕창 먹고 먹튀한 거 봤어?\n",
      "P02: 먹었으면 돈을 내야지\n",
      "P02: 그게 뭐야...\n",
      "P03: 왜 그러는거야 대체?\n",
      "P03: 못된 심보군 키키\n",
      "P01: 내 말이\n",
      "P01: 돈을 떠나서 괘씸하다 키키\n",
      "P02: 대박이네\n",
      "P02: 요즘 세상에 그런 생각도 하고 키키\n",
      "P03: 진짜 돈을 많이 줘도 치우기 싫을 듯 키키\n",
      "P01: 그러게\n",
      "P01: 자영업자 가뜩이나 힘든데 ㅠㅠ\n",
      "P02: 그니까 ㅠㅠ\n",
      "P02: 진짜 나쁜 사람들 많아\n",
      "P03: 그니까\n",
      "P03: 숙박업소 사장님은 무슨 죄야 ㅠㅠ\n",
      "P01: 키키 숙박업소 아니야\n",
      "P01: 고깃집 사장님이야\n",
      "P02: 맞아 키키\n",
      "P02: 너 기사 대충 읽었지~?\n",
      "P03: 아 진짜? 키키\n",
      "P03: 나는 펜션 말하는 줄 키키\n",
      "P01: 노노\n",
      "P01: 저 작은 가게에서 엄청 나게 먹어 댔네\n",
      "P02: 아주 그냥 식성이 좋은 사람들이네 키키\n",
      "P03: 한번 찾아봐야겠네 키키\n",
      "P03: 듣기만 해도 화난다\n",
      "P01: 걔네 완전 계획적이고 상습범이래 키키\n",
      "P02: 그런 걸로 계획을 세우고 그러냐 에이고\n",
      "P03: 진짜 머리를 거기다 쓰냐\n",
      "P03: 너무하다\n",
      "P03: 몇 명이 그런 거야 대체\n"
     ]
    }
   ],
   "source": [
    "from eval import get_eval_data\n",
    "\n",
    "print(get_eval_data()[36])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "response:\n",
       "GenerateContentResponse(\n",
       "    done=True,\n",
       "    iterator=None,\n",
       "    result=protos.GenerateContentResponse({\n",
       "      \"candidates\": [\n",
       "        {\n",
       "          \"finish_reason\": \"SAFETY\",\n",
       "          \"index\": 0,\n",
       "          \"safety_ratings\": [\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
       "              \"probability\": \"MEDIUM\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            }\n",
       "          ]\n",
       "        }\n",
       "      ],\n",
       "      \"usage_metadata\": {\n",
       "        \"prompt_token_count\": 459,\n",
       "        \"total_token_count\": 459\n",
       "      }\n",
       "    }),\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from eval import get_eval_data\n",
    "\n",
    "response = client.generate_content(\n",
    "    contents=get_eval_data()[36],\n",
    "    # safety_settings={\n",
    "    #     HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE\n",
    "    # }\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 별도의 Guardrail 라이브러리\n",
    "- guardrails-ai\n",
    "- NVIDIA-NeMo\n",
    "- guidance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rein20/Documents/lectures/ai-service/kakaotalk-summarization/.venv/lib/python3.12/site-packages/guardrails/validators/__init__.py:51: FutureWarning: \n",
      "    Importing validators from `guardrails.validators` is deprecated.\n",
      "    All validators are now available in the Guardrails Hub. Please install\n",
      "    and import them from the hub instead. All validators will be\n",
      "    removed from this module in the next major release.\n",
      "\n",
      "    Install with: `guardrails hub install hub://<namespace>/<validator_name>`\n",
      "    Import as: from guardrails.hub import `ValidatorName`\n",
      "    \n",
      "  warn(\n",
      "/Users/rein20/Documents/lectures/ai-service/kakaotalk-summarization/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation failed for field with errors: The following sentences in your response were found to be toxic:\n",
      "\n",
      "- You are a stupid idiot who can't do anything right.\n"
     ]
    }
   ],
   "source": [
    "# Import Guard and Validator\n",
    "from guardrails.hub import ToxicLanguage\n",
    "from guardrails import Guard\n",
    "\n",
    "# Use the Guard with the validator\n",
    "guard = Guard().use(\n",
    "    ToxicLanguage, threshold=0.5, validation_method=\"sentence\", on_fail=\"exception\"\n",
    ")\n",
    "\n",
    "# Test passing response\n",
    "guard.validate(\"Love how you think and attack the problem. Great job!\")\n",
    "\n",
    "try:\n",
    "    # Test failing response\n",
    "    guard.validate(\n",
    "        \"Please look carefully. You are a stupid idiot who can't do anything right.\"\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Guard and Validator\n",
    "from guardrails.hub import ToxicLanguage\n",
    "from guardrails import Guard\n",
    "\n",
    "# Use the Guard with the validator\n",
    "guard = Guard().use(\n",
    "    ToxicLanguage, threshold=0.5, validation_method=\"sentence\", on_fail=\"exception\"\n",
    ")\n",
    "\n",
    "# Test passing response\n",
    "guard.validate(\"안녕하세요!\")\n",
    "\n",
    "try:\n",
    "    # Test failing response\n",
    "    guard.validate(\n",
    "        \"바보 멍청이\"\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
